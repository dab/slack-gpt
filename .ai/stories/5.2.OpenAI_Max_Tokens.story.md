# Story 5.2: Make OpenAI `max_tokens` Configurable

## Story

**As a** Developer
**I want** to make the `max_tokens` parameter in the `OpenAIService.get_answer` method configurable
**so that** the maximum length of the generated response can be controlled via environment settings rather than being hardcoded.

## Status

Draft

## Context

Currently, the `max_tokens` value for the OpenAI API call is hardcoded to `500` in `app/services/openai_service.py`. This limits the response length and may truncate potentially longer, valid answers. This story makes the limit configurable.

## Estimation

Story Points: 2 (1 SP=1 day of Human Development, or 10 minutes of AI development)

## Acceptance Criteria

1.  - [ ] `app/utils/config.py` includes a new configuration variable `MAX_RESPONSE_TOKENS` loaded from an environment variable, with a sensible default (e.g., `1024` or a value appropriate for `gpt-4o-mini`'s maximum output).
2.  - [ ] `.env.example` is updated to include `MAX_RESPONSE_TOKENS`.
3.  - [ ] `app/services/openai_service.py` updated:
    *   - [ ] The `get_answer` method retrieves the `MAX_RESPONSE_TOKENS` value from the configuration.
    *   - [ ] The hardcoded `max_tokens=500` in the `client.chat.completions.create` call is replaced with the configured value.
4.  - [ ] Unit tests in `tests/services/test_openai_service.py` updated to verify that the configured `max_tokens` value is used in the API call mock.
5.  - [ ] `README.md` updated to mention the `MAX_RESPONSE_TOKENS` environment variable.
6.  - [ ] `arch.md` updated to reflect the configurable `max_tokens` parameter and the new `MAX_RESPONSE_TOKENS` environment variable.

## Subtasks

1.  - [ ] **Configuration**
    1. - [ ] Add `MAX_RESPONSE_TOKENS` configuration in `config.py`.
    2. - [ ] Add `MAX_RESPONSE_TOKENS` to `.env.example` with a default value.
2.  - [ ] **OpenAI Service Update**
    1. - [ ] Update `get_answer` in `openai_service.py` to use the configured value.
3.  - [ ] **Testing**
    1. - [ ] Update unit tests in `test_openai_service.py` to assert the correct `max_tokens` parameter.
4.  - [ ] **Documentation**
    1. - [ ] Update `README.md`.
    2. - [ ] Update `arch.md`.
5.  - [ ] **Code Quality**
    1. - [ ] Run linters/formatters/type checkers.

## Testing Requirements:

*   Unit tests must verify the `max_tokens` parameter passed to the mocked OpenAI API call matches the configured value.
*   Unit tests for `app/services/openai_service.py` must maintain or exceed >= 70% code coverage.

## Story Wrap Up (To be filled in AFTER agent execution):

*   **Agent Model Used:** `<Agent Model Name/Version>`
*   **Agent Credit or Cost:** `<Cost/Credits Consumed>`
*   **Date/Time Completed:** `<Timestamp>`
*   **Commit Hash:** `<Git Commit Hash of resulting code>`
*   **Change Log**
    *   change X
    *   change Y
    ... 
# Story 5.3: Enhance OpenAI Error Handling for Large Prompts

## Story

**As a** Developer
**I want** to enhance the error handling in `OpenAIService.get_answer`
**so that** it specifically catches errors related to the prompt exceeding the model's context window limit and attempts a retry with potentially reduced context.

## Status

Draft

## Context

When the context provided to the OpenAI API (from PDF chunks) is too large, the API call fails. Currently, this results in a generic error message logged and returned to the handler. This story implements more specific error handling to identify this condition and attempt a single retry with less context.

## Estimation

Story Points: 4 (1 SP=1 day of Human Development, or 10 minutes of AI development)

## Acceptance Criteria

1.  - [ ] `app/services/openai_service.py` updated:
    *   - [ ] The `try...except` block in `get_answer` specifically catches the OpenAI API error indicating the prompt is too large (e.g., `openai.BadRequestError` - investigate the exact error code/message returned by the API for this condition).
    *   - [ ] When this specific error is caught, a warning is logged indicating the prompt was too large.
    *   - [ ] A simple retry mechanism is implemented (e.g., try the API call again *once*).
    *   - [ ] Before retrying, the `context` string is shortened (e.g., truncated by a percentage, or by removing the last chunk if identifiable, or simply halved). The chosen method should be documented.
    *   - [ ] The retry uses the shortened context in the API call.
    *   - [ ] If the retry also fails (for any reason, including prompt still too large), the error is logged and `None` is returned (as before).
2.  - [ ] Unit tests in `tests/services/test_openai_service.py` updated:
    *   - [ ] Add test cases that simulate the OpenAI API raising the specific "prompt too large" error on the first call.
    *   - [ ] Verify that the context is shortened according to the implemented strategy.
    *   - [ ] Verify that the API is called a second time with the shortened context.
    *   - [ ] Verify the behavior if the second call succeeds or fails.
3.  - [ ] `arch.md` updated to document the enhanced error handling strategy (catching specific context limit errors, the retry mechanism, and context shortening approach) within the `OpenAI Service` description or `Error Handling Strategy` section.

## Subtasks

1.  - [ ] **Research & Design**
    1. - [ ] Research and identify the specific OpenAI API error (e.g., `openai.BadRequestError` subclass or specific error code/message) returned when the context limit is exceeded.
    2. - [ ] Decide on and document the context shortening strategy for the retry (e.g., string slicing by percentage, removing last N tokens/chars).
2.  - [ ] **Implementation**
    1. - [ ] Update the `try...except` block in `get_answer` to catch this specific error.
    2. - [ ] Implement the logging for the "prompt too large" condition.
    3. - [ ] Implement the chosen context shortening strategy.
    4. - [ ] Implement the single retry logic within the specific error handler.
3.  - [ ] **Testing**
    1. - [ ] Add new unit tests to `test_openai_service.py` covering the retry logic and context shortening.
4.  - [ ] **Documentation**
    1. - [ ] Update `arch.md` with details on the new error handling/retry logic.
5.  - [ ] **Code Quality**
    1. - [ ] Run linters/formatters/type checkers.

## Testing Requirements:

*   Unit tests must specifically mock the OpenAI API client to raise the "context too large" error and verify the retry logic, context modification, and subsequent API calls.
*   Unit tests for `app/services/openai_service.py` must maintain or exceed >= 70% code coverage.

## Story Wrap Up (To be filled in AFTER agent execution):

*   **Agent Model Used:** `<Agent Model Name/Version>`
*   **Agent Credit or Cost:** `<Cost/Credits Consumed>`
*   **Date/Time Completed:** `<Timestamp>`
*   **Commit Hash:** `<Git Commit Hash of resulting code>`
*   **Change Log**
    *   change X
    *   change Y
    ... 
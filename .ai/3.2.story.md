# Story 3.2: Implement `/ask` Command Handler - Core Flow & Orchestration

## Story

**As a** Developer\
**I want** to implement the core logic and service orchestration for the `/ask` slash command handler\
**so that** the bot can process user questions, check the cache, query the knowledge base and OpenAI, cache the result, and send an asynchronous response.

## Status

Draft

## Context

This is the main story implementing the primary functionality (PRD FR#1). It involves creating the asynchronous handler in `app/handlers/ask_command.py`, registering it, and orchestrating calls to the services created in Epic 2 (`KnowledgeBaseService`, `RedisService`, `OpenAIService`). Key aspects include immediate acknowledgment (`ack()`), asynchronous execution of the main logic, question parsing/normalization, cache key generation (SHA-256 hash as per Arch Doc ADR-004), cache check/hit, context retrieval, OpenAI call (if cache miss), caching the new result, and sending the final answer asynchronously using Block Kit (`respond`). Error handling is covered separately in Story 3.3.

## Estimation

Story Points: 5

## Acceptance Criteria

1.  - [ ] `app/handlers/ask_command.py` created.
2.  - [ ] An asynchronous handler function (e.g., `handle_ask_command`) is implemented.
3.  - [ ] Handler is registered with Bolt app in `app/main.py` via `@app.command("/ask")`.
4.  - [ ] Handler immediately calls `await ack()` upon receiving the command.
5.  - [ ] Handler retrieves the `<question>` text from the `command` payload (`command['text']`).
6.  - [ ] If question text is empty/missing, an asynchronous usage message is sent via `respond()` using Block Kit.
7.  - [ ] Handler instantiates or accesses instances of `RedisService`, `KnowledgeBaseService`, `OpenAIService`.
8.  - [ ] Question text is normalized (e.g., lowercase, remove punctuation, collapse whitespace).
9.  - [ ] A cache key is generated from the normalized question (e.g., SHA-256 hash using `hashlib`).
10. - [ ] `RedisService.get_value(cache_key)` is called.
11. - [ ] If `get_value` returns a cached answer:
     *   - [ ] The answer is formatted using Block Kit.
     *   - [ ] The formatted answer is sent asynchronously via `respond()`.
     *   - [ ] Cache hit is logged (Story 3.4).
12. - [ ] If `get_value` returns `None` (cache miss):
     *   - [ ] Cache miss is logged (Story 3.4).
     *   - [ ] `KnowledgeBaseService.find_relevant_context(raw_question_text)` is called. PDF search logged (Story 3.4).
     *   - [ ] `OpenAIService.get_answer(raw_question_text, context)` is called. OpenAI call logged (Story 3.4).
     *   - [ ] If `get_answer` returns a valid answer:
         *   - [ ] `RedisService.set_value(cache_key, answer, ttl)` is called (TTL e.g., 86400 seconds for 24h).
         *   - [ ] The answer is formatted using Block Kit.
         *   - [ ] The formatted answer is sent asynchronously via `respond()`. Answer sent logged (Story 3.4).
     *   - [ ] (Handling OpenAI failure/not-found is in Story 3.3).
13. - [ ] All potentially long-running operations (service calls, normalization/hashing if complex) happen *after* `await ack()`.
14. - [ ] All I/O operations (service calls, `respond`) use `await`.
15. - [ ] Responses (answers, usage message) use Slack Block Kit.

## Subtasks

1.  - [ ] Create `app/handlers/ask_command.py`.
2.  - [ ] Define `async def handle_ask_command(ack, command, respond, logger, ...)` signature. Inject service instances if using dependency injection, or instantiate them.
3.  - [ ] Add imports for services, `hashlib`, `re` (for normalization), etc.
4.  - [ ] Implement immediate `await ack()`.
5.  - [ ] Extract question text: `question = command.get('text', '').strip()`.
6.  - [ ] Implement check for empty question and send usage message via `await respond(...)` if empty.
7.  - [ ] Implement normalization function (e.g., `lower()`, `re.sub(...)`).
8.  - [ ] Implement cache key generation: `hashlib.sha256(normalized_question.encode()).hexdigest()`.
9.  - [ ] Implement cache check logic: `cached_answer = await redis_service.get_value(cache_key)`.
10. - [ ] Implement cache hit path: format `cached_answer` with Block Kit and `await respond(...)`.
11. - [ ] Implement cache miss path:
    *   - [ ] `context = await knowledge_base_service.find_relevant_context(question)`.
    *   - [ ] `answer = await openai_service.get_answer(question, context)`.
12. - [ ] Implement caching result: `if answer: await redis_service.set_value(cache_key, answer, ttl=86400)`.
13. - [ ] Implement sending OpenAI result: `if answer: await respond(blocks=format_block_kit(answer))`.
14. - [ ] Define `format_block_kit(answer_text)` helper function.
15. - [ ] Register handler in `app/main.py`.
16. - [ ] Manually test the `/ask` command flow (cache miss, then cache hit).

## Testing Requirements:

*   Code coverage requirement >= 70% for `app/services/`. (Handler testing with mocked services recommended post-MVP).

## Story Wrap Up (To be filled in AFTER agent execution):

*   **Agent Model Used:** `<Agent Model Name/Version>`
*   **Agent Credit or Cost:** `<Cost/Credits Consumed>`
*   **Date/Time Completed:** `<Timestamp>`
*   **Commit Hash:** `<Git Commit Hash of resulting code>`
*   **Change Log**
    *   change X
    *   change Y
    ... 